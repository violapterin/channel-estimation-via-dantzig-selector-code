\documentclass[12pt]{article}

\usepackage{mathtools}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage[linkcolor=blue]{hyperref}
\usepackage{xcolor}
\usepackage[ocgcolorlinks]{ocgx2}
\usepackage{stackengine}

\author{Tzu-Yu Jeng}
\date{\today}
\title{Compressive Channel Sensing of Multipath Millimeter Channel via a Beamspace Dantzig Selector and its Probabilitic Performance Bound}

\newcommand{\MB}[1]{\mathbb{#1}}
\newcommand{\MC}[1]{\mathcal{#1}}
\newcommand{\MF}[1]{\mathfrak{#1}}
\newcommand{\RM}[1]{\mathrm{#1}}
\newcommand{\T}[1]{\tilde{#1}}
\newcommand{\V}[1]{\stackunder[1.2pt]{$#1$}{\rule{.9ex}{.075ex}}}
\newcommand{\M}[1]{\V{\V{#1}}}

\newcommand{\LA}{\langle}
\newcommand{\RA}{\rangle}

\newcounter{NumResult}
\newcommand{\myCount}
{
   \stepcounter{NumResult}
   \textbf{\arabic{NumResult}}
}

\newcommand {\Result} [2]
{
   \bigskip
   \myCount \textbf{#1} \par
   {#2} \par
   \hfill \(\blacksquare\)
   \bigskip
}

\begin{document}

\maketitle

\section{Acknowledgement}


\section{Abstract}

Multiple-input-multiple-output (MIMO) communication is widely expected to be the next-generation wireless communication scheme.
However, reliable communication in such r\`egime usually requires that the channel response be known at the receiver, necessary for example in beamforming algorithm and channel calibrupation.
It is then a non-trivial problem to estimate real-world wireless channels.

Meanwhile, in the millimeter wave r\`egime, which is usually used in tandem with MIMO, channel often exhibits sparse properties.
If the sparsity is exploited, few observations may suffice to estimate the channel, and such algorithm falls under the study of compressive sensing, an active area that has recently emerged.
A promiment estimator is The Dantzig Selector (DS) proposed by Tao and Cand\'es, and it is DS which was first applied in channel estimation context.
However, Orthogonal Matching Pursuit (OMP) later emerges as a low-complexity solution, and following-up literature usually used OMP rather than DS as a result.

In this article, we utilize a hybrid structure at both transmitter and receiver end, each of them having both digital and analog percoders and combiners.
We argue in favor of DS, and verify that DS is, as originally perceived, ideal in certain senses.
DS encompasses a more general setting than OMP, such as in its requirement of restricted isometry property (RIP) only, and as in its allowance of noise corruption.
Moreover, we extend their proof to derive a stronger bound in the setting of estimation of millimeter wave channel for almost-sparse channel matrix

We show explicitly that DS may be cast as a second order cone problem (SOCP), and primal-dual technique is ready to be used.
Simulation is done with both DS and OMP, and we discuss their respective merits as our conclusion.

\section{Introduction}

This section is organized as follows.
Before we start, we introduce our notation in the very beginning, since the literature survery quickly goes into technical details.
And we first provide the motivation, and then overview the existent literature on channel estimation.
Particularly, we will summerize present results on DS and OMP, and argue that DS is a viable solution that has been ignored, and then claim our contribution in this article that will be shown in the later sections.

\subsection{Notation}

Before we start, let us remind that, in this article, to avoid confusion all results other than the major theorems to be proved are called lemmata, so the classification may be different from its source.

We restrict our discussion to the Hilbert space over the field of \(\MB{R}\) or \(\MB{C}\), equipped with usual inner product, here the complex numbers has natural interpretation as the phasor of electronic waves.
We use \(\MB{K}\) to refer to either \(\MB{R}\) or \(\MB{C}\).
Lower case Latin alphabets with single underline, like \(\V{a}\), denote vectors, and upper case Latin alphabets with double underlines, like \(\M{A}\), denote matrices.
To avoid being too pedantic, we simply write \(\V{a} \in \MB{C}^N\) to stress \(\V{a}\) is a \(N\)-dimensional vector, and the role it plays in the vector space is understood.
Similarly, we also write \(\V{A} \in \MB{M}(M,N)\) to stress \(\V{A}\) is a \(M\) by \(N\) matrix, and the role it plays as linear transformation is understood.
Inner product is denoted as \(\LA \MB{a}, \MB{b} \RA\).
Slightly abusing notation, denote as \(\V{a}(n)\) the \(n\)-th component of \(\V{a}\), and denote as \(\V{A}(m,n)\) the \((m,n)\)-entry of \(\V{A}\)
Especially, \(\V{u}_n\) is the \(n\)-th unit vector in the Cartesian coordinates (not to be confused with the noise).

\(|a|\) denotes the magnitude for real or complex numbers.
\(\|\V{a}\|_p\) denotes the \(\ell_\infty\)-norm of \(\V{a}\).
Recall that \(\ell_\infty\)-norm is the maximum-magnitude norm.
The real and imaginary part of \(a\) will be denoted respectively as \(\MF{Re}(a)\) and \(\MF{Im}(a)\), respectively, thus \(\MF{Re}(a) +i \MF{Im}(a)\)

Denote as \(\MB{P}(X)\) the probability, \(\MB{E}(X)\) the expectation, \(\MB{Var}(X)\) the variance.
Since our discussion involving the entire communication system will get very complicated, we shall add subscripts on probabilistic integrals, including \(\MB{P}\) and \(\MB{E}\).


\subsection{Background}

Multiple-input multiple-output (MIMO) communication system has been proposed to be the next-generation specification.
With a large number of antennae of both transmitter and receiver sides (hereafter massive MIMO) is therefore expected to improve spectral efficiency.
But MIMO presents new obstacles as well.
The hardware overhead due to large number of antennas increases complexity and power consumption, and new precoders are being invented to take account of this.
It is important to devise a feasible scheme, as the systems themselves are growing more complicated.
Meanwhile, millimeter waves, having smaller wavelength, entails higher frequency bands, and thus wider available bandwith to be available.
In addition, the smaller closer spaced antennae makes it possible to increase the number antennae.
Consequently, this article considers MIMO in the millimeter r\`egime.

The figure of merit of a MIMO system is usually considered to be the channel capacity.
The capacity \(C\) of a MIMO channel \(\M{H}\) at perfect channel state information (CSI) is well-known, as was first proved by Teletar, to be roughly in the form \(\log \det (I +\RM{SNR})\).
But that knowledge is hardly always available.
What makes things more difficult is the case that \(\M{H}\) is determined from not only the noise itself, but also inherent parameter --- such as, in our case, as shall be seen, the angle of departure and arrival.
It is pointed out that the capacity written in explicit dependence of such parameters is a difficult and long-standing problem (Goldsmith et.\ al.\ 2003).
Nevertheless, the perfect-CSI expression of channel capacity is often used regardless of these issues.
Indeed, analysis of precoding algorithm, for example, usually makes use of the sum rate \(\log \det (I +\RM{SNR})\).

Therefore the real-time estimation, \(\hat{\M{H}}\), of \(\M{H}\) is of paramount importance.
Needless to say, when the \(\hat{\M{H}}\) is imprecise, resulting analysis is also undermined.
With more antennae present, conventional training-based algorithm also increase in complexity and storage.
In real applications, channel may also be fast varying with respect to time, and a high complexity algorithm is surely less than being ideal.
A design of new algorithms that addressed these issues is thus in need.


\subsection{Recovery of Sparse Vector in the Noiseless Case}

It is a recent developemnt that the estimation of channels is facilitated by advances of compressed sensing.
A series of paper by Cand\`es and Tao (2006) marks its advent.
The idea is that, in many important statsitical applications, the number of variables or parameters \(p\) is much larger than the number of observations \(n\).
In such case of insufficient observations, possibly even with noise, do we have the knowledge of all \(p\) variables?
Of course, more assumption must be made to make the question meaningful.
Cand\`es and Tao's pioneering work reveals the phenomenon that few observations of the signal in question may be sufficient for us to resonstruct the signal when it is sparse in a certain sense.
They argue that such recovery of signals is possible, if we make a few carefully constructed, and seemingly random measurements.
Ever since, it becomes feasible that a camera equipped with few sensors may obtain high quality images, greatly reducing the subsequent cost.

They showed that that in the noiseless case (Cand\`es and Tao 2006,``Decoding by Linear Programming''), it is possible to recover the sparse signal, under a \(\ell_1\)-1 minimization program.

\Result
{Definition}
{
\(x \in \MB{K}^N\) is called \(s\)-sparse, if
\begin{gather} 
\# \{\RM{supp}(x)\} \leq s
\end{gather}
That is, only at most \(s\) components of vector \(x\) is nonzero.
}

\Result
{Program}
{
Let \(A,y\) be given.
Find \(x\) with
\begin{gather}
\RM{min}_{x' \in \MB{R}^K} \quad \|x'\|_1
\RM{s.t.} \quad Ax =y
\end{gather}
}

\Result
{Theorem}
{
Let \(y =Ax\).
Suppose \(x\) is \(s\)-sparse, then the program () completely recovers \(x\).
That is, a noiseless linear transformation of a sparse vector is completely recovered by a \(\ell_1\)-minization program with an overwhelming probability, if
\begin{gather}
\delta_{S} +\delta_{2S} +\delta_{3S} <1
\end{gather}
}


\Result
{Notation}
{
Let \(T \subset \MB{N}\).
Denote as \(X_T\) the columns of \(X\) having indices in \(T\).
}

\Result
{Definition}.
{
Let \(X\) be an \(n \times p\) matrix having unit \(\ell_2\)-norm columns.
For each integer \(S \in \MB{N}\), we say that \(X\) satisfies the RIP of order \(S\) with respect to parameter \(0 \leq \delta_S \leq 1\), if, for all \(\vartheta\) with \(\|\vartheta\|_0 \leq S\), for all \(T\) with \(|T| \leq S\),
\begin{gather}
(1-\delta_S) \|\vartheta\|^2
\leq \|X_T \vartheta\|_2^2
\leq (1+\delta_S) \|\vartheta\|^2
\end{gather}
}

RIP of order \(S\) is essentially saying that the matrix \(X\) is ``almost isometry'' up to ``relative error'' \(\vartheta_S\).

Moreover, for \(T,T' \subset \{1, \dotsc, p \}\), let \(\vartheta_{S,S'}\) be the smallest constant such that
\begin{gather}
| \LA X_T c, X_{T'} c' \RA |
\leq \vartheta_{S,S'} \cdot \| c \|_2 \|c'\|_2
\end{gather}

\subsection{The Dantzig Selector}

Later Cand\`es and Tao  obtained a stronger result that (``The Dantzig Selector'' Cand\`es and Tao 2006, which will be a main reference of this article), with a convex program called The Dantzig Selector they proposed (hencefore DS), they can recover the noisy case too.
They argues in their work that DS has many advantages, and the error probability is upper bounded quantatively and shown to be vanishingly small.
From the realistic perspective, DS formulates the sparse sensing problem as an \(\ell_2\) minimization problem, which is convex, thus techniques from convex optimization may readily be used.
Indeed, they have put the code on the web for the reader to access and verify (Cand\`es \& Romberg 2005).

For concreteness, consider a liear transformation with noise,
\begin{gather}
y =Ax +z
\end{gather}
where \(z\) is an i.i.d., zero-mean, \(\sigma\)-variance AWGN vector.
How can we hope to estimate \(h\) when, in addition to insufficient observations, there are too few observations?

\Result
{Program}
{
Let \(A,y\) be given.
Find \(x\) with
\begin{gather}
\min_{x' \in \MB{K}^p}  \|\hat{x'}\|_1 \\ \notag
\RM{subject}\; \RM{to} \quad \|A^\dagger r\|_\infty \leq \lambda_p \sigma
\end{gather}
where \(r =y -A \hat{x}\).
}
And it can be shown that this \(\ell_\infty\)-constraint problem may be recast as a linear program.

\subsection{Condition of RIP Linear Transformation}

The constant \(\delta\) in the proof of DS is significant.
Indeed, we may observe that in theorem (), the bound is not tightest when \(\delta=0\), i.e., that \(A\) is fully unitary.

Here, it is not clear at first what matrices serves as the RIP condition.
But later, Baraniuk (2008) have found there is a particularly convenient sufficient condition to verify RIP.

\Result
{Theorem}
{
Let each entry of random matrix \(A \in \MB{V}(M \cdot N)\) be defined as i.i.d.\ Bernoulli with value \(\pm 1/\sqrt{M}\) (that is, Rademacher distribution).
Then, with \(0 <\epsilon <1\),
\begin{gather}
   \MB{P}( |\|Ax\|_2^2 -\|x\|_2^2| \geq \epsilon \|x\|_2^2)
   \leq 2 \exp(-n c_0(\epsilon))
\end{gather}
where we have
\begin{gather}
c_0(\epsilon)
=\epsilon^2/4 -\epsilon^3/6.
\end{gather}
}

\subsection{Compressed Channel Sensing}

We have summarised results in compressed sensing, and we now relate the matter to the communication scenario.
Recall that the overhead of channel estimation has been a concern in the millimeter wave MIMO setting.
Meanwhile, physical evidences suggest that millimeter wave channels can be said to be sparse in the frequency domain in a certain senses.
Some scholars thus has applied compressive sensing techniques to the problem.

One of the first papers, Bajwa et.\ al.\ (2010) argues the \(\ell_0\)-norm of the channel matrix may be bounded by a constant, and in such settings the Dantzig Selector may be applied.
What they explored was the estimation of single-antenna channel response with respect to time.
Another paper by the same group of scholars (Bajwa et.\ al.\ 2008) shows that \(X\) is RIP for overwhelming probability, providing the ground for the former paper.

To explain the idea, consider a simplified scenario.
Let \(x[t] \in \MB{R}^N\) be random instances of i.i.d.\ Rademacher distribution.
Consider a linear time-invariant channel with
\begin{gather}
y[t] =(x[t] \star h[t]) +z[t]
\end{gather}
where \(h[t] \in \MB{R}^L\) is the channel's impulse response, \(x[t] \in \MB{R}^N\) as the input, \(y[t] \in \MB{R}^N\) as the output, and \(z[t] \in \MB{R}^L\) are random instances of i.i.d.\ normalized AWGN, and \(N \gg L\).
Here, if the convolutional relation is expressed by a matrix \(X\), \(X\) is a Toeplitz matrix, so that
\begin{gather}
y =X h
\end{gather}
where \(X\) takes the form
\begin{align}
X
=\begin{bmatrix}
x_1, &0, &\cdots, &0 \\
x_2, &x_1, &\cdots, &0 \\
\vdots, &\vdots, &\ddots, &0 \\
x_N, &x_{N-1}, &\cdots, &x_1
\end{bmatrix}
\end{align}
We seek to get \(h\) in this undertermined system.

Bajwa et.\ al.\ was able to show that \(X\) is RIP of overwhelmingly probability.

\subsection{Orthogonal Matching Pursuit}

Around that time, Tropp and A C Gilbert (2007b) points out if we apply a greedy algorithm called Orthogonal Matching Pursuit, that a i.i.d.\ matrix being generated the similar way as Baraniuk (2008) suggested, may perform sufficiently well, even recover the original signal in an overwhemingly probability too.

The setting here is \(y =Ax\), the noiseless, real-number case.
Same as before, let \(y \in \MB{V}(M)\), \(x \in \MB{V}(N)\) which is \(s\)-sparse, while \(M \ll N\).
We pick up the columns of \(A\) greedily, hoping to correspond to the support of \(x\).

\Result
{Algorithm}
{
\begin{enumerate}
\item
\end{enumerate}
}

\Result
{Theorem}
{
   Following the setting described above, suppose, for \(0 <\delta <1\),
\begin{gather}
   M \geq 16s \log (N/\delta)
\end{gather}
Then   Algorithm () recovers \(x\) completely, with overwhelming probability \(1-\delta\).
}

For the proof, see the technical report: Tropp and A C Gilbert (2007a).

It is interesting to note that, ever since, the direct application of \(\ell_1\)-problem following the orignal Cand\`es-and-Tao approach has been seemingly rare.
Scholars has applied OMP in favor of DS, in the ease of implementation of the former, and OMP becomes perhaps the most widely used channel estimation technique.
To see this, let \(\M{F}\) be the precoder and \(\M{W}\) the combiner, and \(\M{H}\) the channel, and consider the noiseless case.
Let signal \(x\) be sent, and \(y\) be receiverd, that is
\begin{gather}
   \V{y} =\M{W} \M{H} \M{F} \V{x}
\end{gather}

\Result
{Definition}
{
Define \(\RM{vec}(\M{A}) \in \MB{K}^{nm}\) to be the vectorization of \(\M{A} \in \MB{M}(n,m)\).
}

\Result
{Definition.}
{
For \(\RM{vec}(A) \in \MB{M}(n,m)\) and \(\RM{vec}(A) \in \MB{M}(n,m)\)
Define the Kronecker product \(\RM{vec}(A) \in \MB{K}^{nm}\) 
}

With (), scholars often exploit the relation
\begin{gather}
\RM{vec}(Y)
=\big[ (F^\dagger) \otimes W \big] \RM{vec}(\M{H})
\end{gather}

The matrix consisting of the collection of possible response according to available paths --- called the dictionary --- plays the role of the sensing matrix of OMP.
The combiner at the receiver end corresponds to the step where we map the data from high to low dimension.


\subsection{Further development on CSS}

The literature on CSS has since been vast, and we need not and cannot go through all of them here.
Rather, we analyze the respective contribution and weakness on some of the recent seminal papers.

Rao and Lau (2014) considers a distributed algorithm for a MU-MIMO and proposes a modified joint OMP algorithm, with the assumption on the sparsity of the channel and that channels seen by various users shall share the same support.

Alkhateeb et.\ al.\ (2014) suggests an adaptive OMP algorithm, using a (beam) code book with quantized AoA and AoD.

Alkhateeb, Leus, and Heath Jr.\ (2015) poses the interesting trade-off of number of OMP measurement and accuracy in an application of OMP.
They work simplified all-phase-shifter combiner model, where every receiver antenna may only multiply the signal by a constant, and the channel model is assumed to take value on a quantized, non-uniform set of angles.
Their work mainly focuses on numerical simulation, rather than mathematical proof.

Since the notice of hybrid beamforming, scholars have also applied the same idea to hybrid systems.
Lee, Gil, and Lee (2016) considers a hybrid beamforming system, where the composition of the precoders and combineres play the role of sensing matrix.
The beambook phase is quantized, which may have been a source of error, and they have specifed a particular grid set of angles and argues the superiority.
One of their simulations experiments utilizes DFT and permutated DFT matrix, instead of as originally suggested by Tropp and Gilbert (2007).

Meanwhile, the improvement of OMP bound is also going on.
Cai, Wang, and Xu (2010), making assumptions on MIP matrices, give new bound on OMP, and, in addition, Cai and Wang (2011) replicates the same for analysis for DS, among other convex algorithms.
Indeed, MIP deals with correlation of columns of the sensing matrix, rather than the almost-unitarity, making the condition easier to verify.

Ben-Haim et.\ al.\ (2010) follow up their work and refine their bounds, also considering MIP conditions.
They conclude that OMP is better for low-SNR scenario, and DS is better for high-SNR.
Still, since the setting of OMP and DS is rather different, it remains unclear which of is better.

Alkhateeb, Leus, and Heath (2015), being a recent paper, cites Ben-Haim et.\ al.\ (2010) as the main foundation for OMP perfomance bound.

Gao et.\ al.\ (2015) discusses the jointly reconstruction of several high-dimensional sparse signals having the same support, using different measurement matrices in a modified basis pursuit problem.

\subsection{Contribution}

We remark several observation on past literature, that has been, to the best of our knowledge, lacking or less than ideal.

\begin{enumerate}
\item As said, previous work the favor on OMP rather than DS (let alone other sparse algorithm) is evident.
\item In view of The requirement that the sensing matrix should be elementwise i.i.d.\ Gaussian, Tropp and Gilvert (2007) seems to be more restrictive than Cand\`es and Tao (2007).
\item Previous work only takes the assumption on the bound of the norm of the channel matrix to be granted.
\item Likewise, such probability bounds on the sparsity of the channel as involving, say, number of channel paths and vector of array response has not be explored.
\end{enumerate}

We consider a system model where both digital and analog beamformer are i.i.d.\ random matrix combiner that serve readily as the sensing matrix satisfying the RIP property.
We apply a convex program analogous of DS in order to directly estimate the channel under hypothesis of uniform linear array response.
Moreover, inspired by the lines of proof of Cand\`es and Tao (2006), the author gives such an asymptotic bound for the probability will be shown, that indicates our method is successful for overwhelming probability.

Our contribution include:

\begin{enumerate}
\item As a \textit{prima face} difference, we use a modified DS rather than OMP, done on the beamspace rather than the spatial domain, and involving complex numbers rather than real numbers.
\item We do not assume that the virtual channel model is naturally quantized in its angle of departure and of arrival, thus removes concern of the quantization error within the proof.
\item Accordingly, the effect of quantization of the virtual channel's phase angle incorporated in the beambook has been especially considered in the bound.
\item Moreover, an explicit bound has been shown to provide realistic guide for engineering, where the sparsity of the virtual channel matrix, rather than just assumed, is written out as a function of the number of paths of the channel.
\item We derive explicitly the SOCP problem and afterwards its dual problem, and wrote a proof-of-concept but efficient code.
\end{enumerate}

\section{Problem Setting}

\subsection{Channel Model}

Since expression involving probability will get very complecated, introduce the direct product
%
\begin{gather}
\Omega
=\Omega_t \times \Omega_h \times \Omega_n \times \Omega_r
\end{gather}
%
to denote the overall sample space, where
%
\begin{itemize}
\item \(\Omega_t\) denotes the collection of probability samples at the transmitter end,
\item \(\Omega_h\) denotes that of the communication channel,
\item \(\Omega_h\) denotes that of the noise arising in the communication channel,
\item \(\Omega_r\) denotes that at the receiver end.
\end{itemize}
%
\(\omega_1\) stands for the event space index of the transmitter end, and \(\omega_2\) for the channel, and \(\omega_3\) for the receiver.


We restrict our consideration to the uniform linear array, which can be modeled as
\begin{gather}
\V{a}(\varphi')
=\sum_{n=1}^{N} \RM{e}^{n \varphi' i} \V{u}_n
\end{gather}
where \(i\) is the imaginary unit, \(\V{u}_n\) is the unit vector of the \(n\)-th component.

And consider the virtual representation of the MIMO channel (see for example Akdeniz et.\ al.\ 2014).
\begin{gather}
H
=\sum_{l=0}^L \alpha_l \V{a}\big( \frac{d}{\lambda} \sin \varphi_l' \big) \V{a}\big( \frac{d_{\RM{arr}}}{\lambda} \sin \vartheta_l' \big)^\dagger
\end{gather}
The physical meaning of \(\vartheta_l\) is the \(l\)-th angle of incidence (formed by the ray and the normal line) of departure electronic wave, and \(\vartheta_l\), the \(l\)-th that of arrival wave, while \(d_{\RM{arr}}\) is the distance between two adjacent antennae.
For our purpose, we may absorb the argument of \(\V{a}\) as
\begin{gather}
\varphi_l
=\frac{d_{\RM{arr}}}{\lambda} \sin \varphi_l' \\
\vartheta_l
=\frac{d_{\RM{arr}}}{\lambda} \sin \vartheta_l'
\end{gather}
to get a simpler form
\begin{gather}
H
=\sum_{l=0}^L \alpha_l \V{a}(\varphi_l) \V{a}(\vartheta_l)^\dagger
\end{gather}

\Result
{Definition.}
{
}

\subsection{System Model}

We consider the situation with a hybrid structure at both transmitter and receiver end.
Each end consists of both digital and analog percoders and combiners.
In the transmitter end, there are digital precoder \(F_B\) and analog precoder \(F_R\).
Similarly, in the receiver end, there are digital combiner \(W_B\) and analog combiner \(W_R\).
To set up notation, we list them as below.
\begin{gather}
F_B \in \MB{C}^{N_r \cdot N_y} \\
F_R \in \MB{C}^{N_h \cdot N_r} \\
F_B \in \MB{C}^{N_r \cdot N_h} \\
F_B \in \MB{C}^{N_y \cdot N_r}.
\end{gather}
Recall that analog precoder is restricted to have value with magnitude being unity.
\begin{gather}
 |F_R(n_1,n_2)| =1, \quad
 n_1 =1, \dotsc N_h, \quad
n_2 =1, \dotsc N_r \\
 |W_R(n_1,n_2)| =1, \quad
 n_1 =1, \dotsc N_r, \quad
n_2 =1, \dotsc N_h
\end{gather}

And we consider zero-mean, unity-variance additive white Gaussian noise \(z\).
Since we restrict our discussion to a specific slice of time, the signal \(z\) degrades as a entrywise i.i.d.\ standard normal distribution vector.

In summary, the effective channel may be written as
\begin{gather}
Y (\omega_h, \omega_e)
:=W_B(\omega_r) W_R(\omega_r) ( H(\omega_h) F_R(\omega_t) F_B(\omega_t) +Z(\omega_z) )
\end{gather}
Supress the event space index for brevity, we restate the same equation as
\begin{gather}
Y
:=W_B W_R ( H F_R F_B +z )
\end{gather}

\subsection{Proposed Method}

The effective channel \(\M{Y}\) has \(N_y\) columns, but to estimate it, we may agree to send one pilot signal, which is one of the standard basis, at a time, namely \(\V{u}_n\).
This way, we may denote the acquired effective channel matrix \(\M{Y}\) under noisy observation as (borrowing Matlab's colon notation to denote columns)
\begin{gather}
\M{Y}(:,n)
:=\M{W}_B \M{W}_R ( \M{H} \M{F}_R \M{F}_B \V{u}_m +\V{z} ), \quad
n =1, 2, \dotsc, N_y
\end{gather}
The crux of the matter is the recovery of \(\M{H}\) with knowledge of \(\M{Y}\), and of course \(\M{W}_R, \M{W}_B, \M{F}_R, \M{F}_B\) which are in our control.

Following previous work on CSS, we write
\begin{gather}
\V{h} := \RM{vec}(\M{H}) \\
\V{y} := \RM{vec}(\M{Y}) \\
\M{P}' :=(\M{F}_R \M{F}_B) \otimes (\M{W}_B \M{W}_R)
\end{gather}
to formulate our goal as sparse recovery problem of \(\RM{vec}(H)\) to be
\begin{gather}
\V{y} =\M{P}' \V{h} +\V{z}
\end{gather}
But, as we have motivated in previous sections, we want to elimitate the angle grid quantization problem, and we want to use DS by considering sparse vector.
What shall we do?

Introduce the discrete Fourier matrix \(K\) defined to be
\begin{gather}
\M{K} \in \MB{M}(N_h, N_h) \\
\M{K}(n_1, n_2) =\frac{1}{\sqrt{N}} \RM{e}^{2\pi i n_1 n_2 /N},
\quad n_1, n_2 =0,1,2,\dotsc, N-1
\end{gather}
where \(i =\sqrt{-1}\).
And observe that, if we write
\begin{gather}
\M{G}
=\M{K}^\dagger \M{H}
\end{gather}
which has the interpretation as the spatial frequency domain representation of \(H\), then
\begin{gather}
\M{Y}
:=\M{W}_B \M{W}_R \M{K} ( \M{G} \M{F}_R \M{F}_B +\M{K}^\dagger \M{Z} )
\end{gather}
If at the end of day, \(G\) is sparse, then we recover \(G\) instead, and our use of DS is fully justified.
To the best of our knowledge, no work has explicitly considered the beamspace CSS.

That is to say, \(K^\dagger z\) may be absorbed, and a similar Kronecker product may be used.
\begin{gather}
\RM{vec}(Y)
\approx \big[ (F_B^\dagger F_R^\dagger) \otimes (W_B W_R K) \big] \RM{vec}(H)
\end{gather}
To simplify notation, set 
\begin{gather}
P =(F_B^\dagger F_R^\dagger) \otimes (W_B W_R K)
\end{gather}
The instances of \(P\) is completely determined in the transmitter and receiver end, that is
\begin{gather}
P =P(\omega_t, \omega_r)
\end{gather}
If so, our program reads

\Result
{Program}
{
Let \(H(\omega_h, \omega_n)\) be the virtual channel, and \(W_R(\omega_r)\) the random analog combiner, \(W_B(\omega_r)\) the random analog combiner, \(F_R(\omega_t)\) the random analog combiner, \(F_B(\omega_t)\) the random analog combiner, and \(K\) the discrete Fourier matrix, all as described in previous sections.
Suppose \(Y\) is the acquired effective channel matrix under corruption of noise \(z\).
\(P\) is defined just above in ().
Then, with parameter \(\gamma\) specified, define the following program
\begin{gather}
\hat{g}
=\underset {{h}} {\RM{min}} \|h\|_1 \quad
\RM{s.t.}\;\; \|P^\dagger (y -P h)\|_\infty \leq \gamma
\end{gather}
And convert \(\hat{g}\) back to the space domain as
\begin{gather}
\hat{h}
=K \hat{g}.
\end{gather}
And finally recover the estimated \(H\) as
\begin{gather}
\hat{H} =\RM{vec}^{-1} (\hat{h})
\end{gather}
}

It, then, will not be hard to establish Cand\`es and Tao's result to the setting of millimeter wave virtual channel, and resulting bound is immediate under straighforward work, as follows.

\section{Results and Proofs}

We follow the argument outlined in ``The Dantzig Selector'' and fill the content.
The sparse vector to be recovered of our investigation is \(g \in \MB{C}^{N_h^2}\), and we continue to use \(\hat{g}\) to denote the Dantzig Selector.

We first establish a technical lemma that shows \(\RM{supp}(g)\) has roughly cardinal \(L\).
At the heart of the argument, the lemma provides the basis on which \(g\) is almost-sparse.

Consider
\begin{gather}
d =g -\hat{g}
\end{gather}
And let
\begin{itemize}
\item \(\MC{A}\) be the largest \(L\) position of \(g\).
\item \(\MC{B}\) be the largest \(L\) position of \(d\) except on \(\MC{A}\).
\item \(\MC{C} =\{1, \dotsc, N_h^2\} -( \MC{B} \cup \MC{C} )\), i.e., the complementary index set.
\end{itemize}
So \(\MC{A}, \MC{B}, \MC{C}\) are mutually exclusive index sets by construction:
\begin{gather}
\MC{A}, \MC{B}, \MC{C} \subset \{1, \dotsc, N_h^2\} \\
   \MC{A} \cap \MC{B} =\MC{B} \cap \MC{C} =\MC{A} \cap \MC{C} =\varnothing \\
\MC{A} \cup \MC{C} \cup \MC{C} =\{1, \dotsc, N\}.
\end{gather}


\Result
{Lemma.}
{
Let \(\varphi(\omega_h)\) and \(\vartheta(\omega_h)\) be both uniformly, independently distributed in \([0,2\pi)\), and beamspace channel matrix \(G\) defined as in ().
\begin{gather}
\|g_{\MC{A}}\|_1 \leq \frac{1}{\pi^2} \log \frac{L}{N}.
\end{gather}
}

To find the \(l\)-th path's contribution to the frequency domain, recall the identity for Dirichlet kernel
\begin{align}
D(\varphi)
:=&\left| \sum_{n=0}^{N-1} \RM{e}^{i n \varphi} \right| \\ \notag
=&\frac{|\sin(N \varphi/2)|}{|\sin(\varphi /2)|},
\quad 0 \leq \varphi \leq \pi
\end{align}
where \(\RM{e}\) is the base of natural logarithm, and \(i =\sqrt{-1}\).

By taking the first two term of the expansion
\begin{align}
\sin x =x -x^3/6 + \MC{O}(x^5), \quad x \ll 1
\end{align}
and noting the monotony of the first two terms,
\begin{align}
D(\varphi)
\leq& \frac{1}{\varphi/2 -(\varphi/2)^3/6} \notag \\
=& \frac{-48}{\varphi^3 -24\varphi}
\quad 0 \leq \varphi \leq \pi,
\end{align}
The fraction above can be bounded.

By the same token, more generally,
\begin{align}
&\left| \frac{1}{N} \sum_{n=0}^{N-1} \RM{e}^{-2\pi i k n/N} \RM{e}^{i n \varphi} \right| \notag \\
=&\frac{1}{N} S(\pi \varphi') \notag \\
\leq& \frac{48}{N \pi^3 (\varphi'^3 -24 \varphi' /\pi^2)}
\end{align}
where \(\varphi' =k/N -\varphi/2\pi\), and the cubic expression is split.
We wish to bound the tail of \(S(\pi \varphi')\), and apply the na\"ive bound
\begin{align}
&\frac{N}{2\pi} \cdot \frac{48}{N \pi^3} \int_{L/N}^1 \frac{1}{\varphi'^3 -24 \varphi' /\pi^2}
 d\varphi' \notag \\
=&\frac{1}{2\pi^2} \cdot \left( 2 \log \frac{L}{N} +\log \frac{24-\pi^2}{24-\pi^2 L^2 /N^2} \right) \notag \\
\leq& \frac{1}{\pi^2} \log \frac{L}{N}
\end{align}
Here, the integral in the first line is immediate.
The second term in the bracket is smaller than 0 and is dropped in the last inequality.
The proof of Lemma () is complete.

The bound is satisfying enough, though refinement is surely possible.
Indeed, \(\log L/N \to 0\) as \(N \to \infty\) and limited by the number of paths \(L\).
Intuitively, this says that when there are few paths, but many antennas, we expect the spatial frequency domain of the virtual channel to be sparse too.

The rest follows ``The Dantzig Selector'' very closely.


\Result
{Proposition}
{
Let \(h \in \MB{R}^n\) and \(\eta \in \MB{R}^p\) are defined as in ().
Then
\begin{align}
\|d_{BC}\|_1
\leq \|d_{\MC{A}}\|_1 +\|g_{BC}\|_1
\end{align}
}

To show this, observe
\begin{align}
&\|g\|_1 -\|d_{\MC{A}}\|_1 +\|d_{BC}\|_1 -\|g_{BC}\|_1 \\
\leq& \|g +d\|_1 \notag \\
\leq& \|g\|_1
\end{align}
In the first line, we recall \(g =g_{\MC{A}}\).

\Result
{Lemma}
{
\begin{align}
|\LA e, P_{:,j} \RA| \leq \sqrt{2 \log p}
\end{align}
}

\Result
{Lemma}
{
\begin{align}
\|P^\dagger P d\|_\infty
\leq& 2 \sqrt{2 \log p}.
\end{align}
}

To show this, start with
\begin{align}
\LA e -r, P_{:,j} \RA
=\LA P \hat{g} -P g, P_{:,j} \RA
=\LA P g, P_{:,j} \RA
\end{align}
Result follows from triangle inequality, and Lemma ().

From ``Dantzig Selector'' (Cand\`es and Tao 2007), Lemma 1, first equation, we have the result below.
The original result is for real vector spaces, but we have checked that the proof is completely valid in complex vector spaces.
Of course the interpretation of modulus and the inner product changes accordingly.

\Result
{Lemma}
{
\begin{align}
\|d_{\MC{A}}\|_2
\leq \frac{1}{1-\delta} \|P^\dagger_{\MC{A}\MC{B}} P \eta\|_2 +\frac{\vartheta}{(1-\delta) \sqrt{L}} \|d_{BC}\|_1
\end{align}
}

From ``Dantzig Selector'' (Cand\`es and Tao 2007), Lemma 1, second equation, we have the result below.
Again, their proof works with complex vector spaces in place of real ones.

\Result
{Lemma}
{
\begin{align}
\|d\|_2^2
\leq \|d_{\MC{A}\MC{B}}\|_2^2 +\frac{1}{L} \|d_{\MC{C}}\|_1^2
\end{align}
}

We can formulate our main theorem.

(To be done)

\section{Simulation}

With the preperation of notation in the previous section, and a discussion on its theory, we shall now formulate our algorithm and focus on the practical aspect.

As of now, we have transformed the sparse-recovery problem of complex matrix \(H\) to complex vector \(h\), and finally to real vector \(\MC{R}(h)\).
But it is not the end.
In fact, Cand\`es and Tao's analysis in ``\(\ell_1\)-magic'' transforms DS into a linear program (LP), but that does not directly applies
Actually they pointed out that complex DS may be cast into a second order cone program (SOCP), but (as they admit in the paper) they did not pursue the matter.
Since the proof is, for the present purpose, not entirely trivial, we include here for completeness of exposition.
Thus our proposed algorithm is not a corollary of the DS program outlines in ``\(\ell_1\)-magic''.

\subsection{Transformation into Second Order Cone Problem}

Since our setting is slightly different from ``\(\ell_1\)-Magic'', for completeness of exposition we write down derivation of the dual problem from the primal problem, as follows.
Recapitulate that, as we explained in the above, DS involves the calculation of \(\ell_1\)-1 norm.
This, for real vectors, can be transformed into a linear program (LP).
But in the complex case, that becomes a quadratic expression of the real and imaginary part of the vector, and is no longer equivalent to an LP.
Still, the comparison arising from primal-dual problem is not easily done in complex numbers, and we cast it into a real \(\ell_1\)-1 norm problem.
Afterwards we will further transform the SOCP to a primal-dual algorithm, which is a well-known technique for convex optimization problems.
The bound in the previous section is valid, since in the course of transformation, nothing is lost or weakened.

For convenience, define the following function that maps a complex vector to the real representation of it.

\Result
{Definition}
{
For \(x \in \MB{R}^N\), We say \(\MC{R}(x) \in \MB{V}(2N)\) is the real representation of \(x\), defined by
\begin{gather}
x \in \MB{V}(2N^2) \notag \\
x(n) =
\begin{cases}
\MF{Re}(x(n)), &n =2n' \\
\MF{Im}(x(n)), &n =2n'+1
\end{cases} \\
n' =1, \dotsc, N \notag
\end{gather}
}

A moment's reflection shows the following definition of real representation of matrices.

\Result
{Definition}
{
For \(A \in \MB{M}(N_1,N_2)\), We say \(\MC{R}(A) \in \MB{M}(2N_1,2N_2)\) is the real representation of \(A\), defined by
\begin{gather}
A \in \MB{V}(2N^2) \notag \\
A(n_1,n_2) =
\begin{cases}
\MF{Re}(A(n_1,n_2)), &n_1 =2n_1'-1,\; n_2 =2n_2'-1  \\
\MF{Im}(A(n_1,n_2)), &n_1 =2n_1',\; n_2 =2n_2'-1  \\
-\MF{Im}(A(n_1,n_2)), &n_1 =2n_1'-1,\; n_2 =2n_2'  \\
\MF{Re}(A(n_1,n_2)), &n_1 =2n_1',\; n_2 =2n_2'  \\
\end{cases} \\
n_1' = 1, \dotsc, N_1 \notag \\
n_2' = 1, \dotsc, N_2 \notag
\end{gather}
}

We continue the notation of program ().

\begin{gather}
\V{\T{y}}
=\MC{R}(y) \in \MB{V}(N_h) \\
\V{\T{g}}
=\MC{R}(g) \in \MB{V}(N_h) \\
\M{\T{P}}
=\MC{R}(\M{P}) \in \MB{M}(2 N_y^2, 2 N_h^2)
\end{gather}
such that
\begin{gather}
\V{\T{y}} =\M{\T{P}} \V{\T{g}} +\V{\T{z}}
\end{gather}
where by construction
\begin{gather}
\V{\T{z}}
=\MC{R}(\V{z}) \in \MB{V}(N_y)
\end{gather}

Finally, introduce these indicator matrices to identify the place where we want to take \(\ell_2\)-norm.

\begin{gather}
I_{n_y}^{(y)} \in \MB{M}(N_y, N_y) \\
I_{n_y}^{(y)}(n_y')
=\begin{cases}
1, &n_y' =2n_y \quad \RM{or} \quad n_y' =2n_y+1 \notag \\
0, &\RM{otherwise}
\end{cases} \\
n_h =1, \dotsc, N_h \notag \\
I_{n_h}^{(h)} \in \MB{M}(N_h, N_h) \\
I_{n_h}^{(h)}(n_h')
=\begin{cases}
1, &n_h' =2n_h \quad \RM{or} \quad n_h' =2n_h+1 \notag \\
0, &\RM{otherwise}
\end{cases} \\
n_h =1, \dotsc, N_h \notag
\end{gather}

If we introduce vector \(\V{m}\) to denote the entrywise complex modulus, we see that Program () now take the form

\Result
{Program}
{
Given are \(\T{P}, \T{y}, \gamma\).
Find \(\T{g}\) with
\begin{gather}
   \min_{\T{g}, \V{m}} \LA \V{1}, \V{m} \RA \notag \\
\RM{s.t.}
\begin{cases}
\| I_{n_h}^{(h)} \T{g} \|_2
   \leq \LA \V{y}_{n_h}, \V{m} \RA \\
\| I_{n_y}^{(y)} \T{P}^\dagger ( \T{P} \T{g} - \T{y} ) \|_2
\leq \gamma  \\
\end{cases}
\end{gather}
where \(\V{1}\) is the all-1 vector.
}

which is an SOCP.

We further rewrite Program () into a stricter, extended block matrix form to make the point clearer.

\subsection{Primal-Dual Interior Point Algorithm}

It remains to convert primal-dual interior point algorithm to make the SOCP easier to calculate.
Of course it is not the only way to do this.
We mention, again, Boyd and Vandenberghe (2004), \textit{Convex Optimization} chap.11 as a standard reference, and ``\(\ell_1\)-MAGIC'' (Cand\`es and J Romberg 2005) for discussion of application to DS.

To clarify notation and for complentess of exposition, we derive the dual problem here.
Start with the Lagrangian \(\MC{L}\), where we note we have to introduce one auxiliary vector and one auxiliary scalar for each \(\ell_2\)-norm constraint.

\begin{align}
   &\MC{L}(\V{m}, \T{g}, \mu^{(h)}, \mu^{(y)}, \lambda^{(h)}, \lambda^{(y)}) \notag \\
=& \LA \V{1}, m \RA 
   +\sum_{n_h} \big[ \LA \mu^{(h)}, I_{n_h}^{(h)} \T{g} \RA -\lambda^{(h)} \LA \V{y}_{n_h}, \V{m} \RA \big] \notag \\
\quad & +\sum_{n_y} \big[ \LA \mu^{(h)}, I_{n_y}^{(y)} \T{P}^\dagger ( \T{P} \T{g} -\T{u} ) \RA -\lambda^{(h)} \gamma \big]
\end{align}


\section{Conclusion and Future Work}

This article applies DS rather than OMP, like many of previous work, as the algorithm via which we estimate the millimeter wave channel.

We should keep in mind that DS goes not without criticism for large complexity of it (Friedlander and Saunders 2007).
Indeed it is clear, even from the primal-dual implementation above, that DS requires memory for large dimensional vector, but OMP does not.

And a meaningful comparison of bounds of OMP and DS is not easy, as their settings are somewhat different.
The author thus criticises the tendency of current literature to mix up results for DS and OMP without clear justification.
It is however not trivial to make meaningful comparison, since their setting is different.
Indeed, the distinction is slight but definite.
DS calls for a RIP matrix and guarantees such performance even in noisy observation (Cand\`es and Tao 2005, 2007), while RIP is not easily to justify rigorously, and its easy construction is even an open problem.
On the other hand, as of OMP, besides the original justification of entrywise i.i.d.\ Gaussian sensing matrix (Tropp and Gilbert 2007a), and existent attempt to characterize MIP condition, there is much to be done OMP for Gaussian.

Since, as we have seen, bounds of performance in different setting are often nontrivial to obtain, and one cannot think OMP, or indeed every algorithm, as a universal solution.
OMP trades off precision for time and space complexity, and for DS the other way around is true, hence we cannot say which is definitely better than the other.
All in all, different problems requires different technique and algorihm within the current constraint, as is probably true in every discipline of engineering.

\section{References}

References are sorted first with alphabetical order, then, in case for exactly the same author(s), with year.

\begin{enumerate}

\item M R Akdeniz et.\ al.\ (2014), ``Millimeter Wave Channel Modeling and Cellular Capacity Evaluation'', \textit{IEEE Journal on Selected Areas in Communications}, Vol.\ 32, No.\ 6

\item A Alkhateeb, O E Ayach, G Leus, and R W Heath Jr (2014), ``Channel Estimation and Hybrid Precoding for Millimeter Wave Cellular Systems'', \textit{IEEE Journal of Selected Topics in Signal Processing}, Vol.\ 8, No. 5.

\item A Alkhateeb, G Leus, and R W Heath Jr.\ (2015), ``Compressed Sensing Based Multi-User Millimeter Wave Systems: How Many Measurements are Needed?'' \textit{IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}

\item W U Bajwa, J Haupt, A M Sayeed, and R Nowak (2010), ``Compressed Channel Sensing: A New Approach to Estimating Sparse Multipath Channels'', Proceedings of the IEEE, Vol.98, No.6.

\item W U Bajwa, J Haupt, G Raz, and R Nowak (2008), ``Compressed Channel Sensing'', 2008 42nd Annual Conference on Information Sciences and Systems.

\item R Baraniuk, M Davenport, R DeVore, and M Wakin (2008), ``A Simple Proof of the Restricted Isometry Property for Random Matrices'', \textit{Constructive Approximation} \textbf{28}: 253–263

\item Zvika Ben-Haim, Y C Eldar, and M Elad (2010), ``Coherence-Based Performance Guarantees for Estimating a Sparse Vector Under Random Noise'', \textit{IEEE Transactions on Signal Processing}, Vol.\ 58, No.\ 10.

\item S Boyd, L Vandenberghe (2004), \textit{Convex Optimization}. Cambridge U.\ Press.

\item E J Cand\`es, J Romberg, and T Tao (2006), ``Robust Uncertainty Principles: Exact Signal Reconstruction From Highly Incomplete Frequency Information'' \textit{IEEE Transactions on Information Theory}, Vol.52, No.2.

\item E J Cand\`es and J Romberg (2005), ``\(\ell_1\)-MAGIC: Recovery of Sparse Signals via Convex Programming'', Retrieved from \url{https://statweb.stanford.edu/~candes/l1magic/downloads/l1magic.pdf}.

\item E J Cand\`es and T Tao (2005), ``Decoding by Linear Programming'', \textit{IEEE Transactions on Information Theory}, Vol.51, No.12.

\item E J Cand\`es and T Tao (2006), ``Near-Optimal Signal Recovery From Random Projections: Universal Encoding Strategies?'' \textit{IEEE Transactions on Information Theory}, Vol.52, No.12.

\item E Cand\`es and T Tao (2007), ``The Dantzig Selector: Statistical Estimation when \(p\) is Much Larger than \(n\)'', \textit{The Annals of Statistics}, Vol.35, No.6.

\item T T Cai and L Wang (2011), ``Orthogonal Matching Pursuit for Sparse Signal Recovery With Noise'', \textit{IEEE Transactions on Information Theory}, Vol.\ 57, No.\ 7.

\item T T Cai, L Wang, and G Xu (2010), ``Stable Recovery of Sparse Signals and an Oracle Inequality'', \textit{IEEE Transactions on Information Theory}, Vol.\ 56, No.\ 7.

\item M P Friedlander and M A Saunders (2007), ``Discussion: The Dantzig Selector: Statistical Estimation when \(p\) is Much Larger than \(n\)'', \textit{The Annals of Statistics}, Vol.\ 35, No.\ 6.

\item Z Gao, L Dai, Z Wang, and S Chen (2015). ``Spatially Common Sparsity Based Adaptive Channel Estimation and Feedback for FDD Massive MIMO'', \textit{IEEE Transactions on Signal Processing}, Vol.\ 63, No.\ 23.

\item A Goldsmith, S A Jafar, N Jindal, and S Vishwanath (2003), ``Capacity Limits of MIMO Channels'', \textit{IEEE Journal on Selected Areas in Communications}, Vol.\ 21, No.\ 5.

\item R W Heath Jr, N González-Prelcic, S Rangan, W Roh, and A M Sayeed (2016), ``An Overview of Signal Processing Techniques for Millimeter Wave MIMO Systems'', \textit{IEEE Journal of Selected Topics in Signal Processing}, Vol.\ 10, No.\ 3.

\item J Lee, G-T Gil, and Y H Lee (2016), ``Channel Estimation via Orthogonal Matching Pursuit for Hybrid MIMO Systems in Millimeter Wave Communications'', \textit{IEEE Transactions on Communications}, Vol.\ 64, No.\ 6.

\item H Li, Q Gao, R Chen, R Tamrakar, S Sun, and W Chen, ``Codebook Design for Massive MIMO Systems in LTE'', \textit{2016 IEEE 83rd Vehicular Technology Conference (VTC Spring)}.

\item X Rao and V K N Lau (2014), ``Distributed Compressive CSIT Estimation and Feedback for FDD Multi-User Massive MIMO Systems'', \textit{IEEE Transactions on Signal Processing}, Vol.\ 62, No.\ 12.

\item J A Tropp and A C Gilbert (2007a), ``Signal Recovery from Random Measurements via Orthogonal Matching Pursuit: The Gaussian Case'', Caltech, ACM Tech.\ Rep. Retrieved from: \url{www.acm.caltech.edu/~jtropp/reports/TG07-Signal-RecoveryTR.pdf}

\item J A Tropp and A C Gilbert (2007b), ``Signal Recovery From Random Measurements via Orthogonal Matching Pursuit'', \textit{IEEE Transactions on Information Theory}, Vol.\ 53, No.\ 12.


\end{enumerate}

\end{document}
