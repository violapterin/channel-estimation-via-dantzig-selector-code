\startchapter [title={Theorems and Proofs}]

Our plan is first to show that \m {\SB {\V {g}}} is almost sparse, and substitute the bound into the expected square error of DS, thus generalizing the original argument.
We will continue to use the variables \m {\V {P}}, \m {\V {g}}, \m {\V {y}}, and \m {\V {z}} introduced in previous sections.

\startsection [title={Almost-Sparsity of Angular Channel}]

Let \m {\hat {\V {g}}} be the Dantzig Selector.
For concreteness, we set
\Disp {
\NC \g 
= \NC \R {2 \log N_h} \NR[+]
}

Other values are of course possible, but this is enough to illustrate our purpose.
Also set for short
\Disp {
\NC \V {d} 
= \NC \hat {\V {g}} -\V {g} \NR[+]
}
And call
\startitemize [1]
\item \m {\MC {A}} be the largest \m {s} position of \m {g}.
\item \m {\MC {B}} be the largest \m {s} position of \m {d_{T\SB {N_h} -\MC {A}}}.
\item \m {\MC {C} =T \RB {N_h} -\MC {A}}, i.e., the complementary index set of \m {\MC {A}}.
\stopitemize

Suppose \m {\M {A} \in \MB {M}_{\MB {K}} \RB {N_1, N_2 }}.
For brevity, let \m {\MC {T} \subset T \RB {N_2 }}.
Denote as \m {\M {A}_{\MC {T}}} the columns of \m {\M {A}} having indices in \m {\MC {T}}.

And Denote the sorting function to be \m {\MC {S}:\; \MB {V}_{\MB {K}} \SB {N} \mapsto \MB {V}_{\MB {K}} \SB {N}}, \m {N \in \MB {N}}, be the sorting function for \m {x \in \MB {V}_{\MB {K}} \SB {N})}, so that
\Disp {
\NC \Nm {\MC {S} \SB {\V{x}} \DB {n_1}} \geq \NC \Nm {\MC {S} \SB {\V{x}} \DB {n_2}}, \NR[+]
\NC n_1 \leq \NC n_2,
\quad n_1, n_2 \in T\RB {N} \NR
}
That is, \m {\V{x}} is sorted in magnitude.
For definiteness, we may compare the first component first, and the second, and so on.
If still there is a tie for a certain component (for complex numbers), the order is irrelevent.

\Result
{Definition}
{
For \m {\V {x} \in \MB {V}_{\MB {K}} \SB {N}}, we say \m {\V {x}} is almost-\m {s}-sparse according to the \m {\ell_p}-norm with remainder \m {R}, if
\Disp {
\NC \Nm {\RB {\MC{S} \SB {\V {x}} \SB {n}} \DB {s:N}}_p
\leq \NC R. \NR[+]
}
}

Let \m {\f} be fixed.
What we have to bound is
\Disp {
\NC R^2
=\NC \sum_{n_H =s}^{N_H -1}
   \RB {\MC{S} \SB {\M {K}^\Adj \V {a} \SB {\f}}} \DB {n_H} ^2 \NR[+]
}

Introduce
\Disp {
\NC \psi \SB {\f, n_H}
:=\NC \RB {
   \RB {
      \RB {\f \; \Rm{mod}\; \F{2\pi}{N_H}}
      +\F {2 \pi n_H} {N_H}
      +\pi
   } \;
   \Rm{mod}\; \RB {2\pi}
}
-\pi
}
so that
\Disp{
\NC \Nm {\psi \SB {\f, n_H}}
\leq \NC \pi
}
And define \m {D} to be the Dirichlet kernel
\Disp {
\NC D \SB {\psi'}
:= \NC \sum_{n_H=0}^{N_H-1} \Ss {e}^{i n_H \psi'} \NR
\NC \quad 0 \leq \NC  \psi' \leq \pi \NR
}
Then observe
\Disp {
\NC \RB {\M {K}^\Adj \V {a} \SB {\f}} \DB {n_H}
=\NC \F {1}{N_H} D \SB {\psi \SB {\f, n_H}} \NR
}

Now, it can be verified that
\Result
{Lemma}
{
For \m {-\pi \leq x < \pi}, we have
\Disp {
\NC \Nm {x - \F {x^3}{6}} \leq \NC \Nm {\sin x}. \NR[+]
}
}
Applying Lemma () to the denominator of () and bounding the nominator by 1, we have
\Disp {
\NC \Nm {D \SB {\psi'} }
= \NC \F {\Nm {\sin \SB {N_H \psi'/2}}}{\Nm {\sin \SB {\psi' /2}}} \NR
\NC \leq \NC B \SB {\psi'} \NR
\NC := \NC \F {48}{\Nm {\psi'^2 -24} \Nm {\psi'}} \NR[+]
\NC -\pi \leq \NC \psi' < \pi. \NR
}
Thus,
\Disp {
\NC R^2
=\NC \F {1}{N_H^2}
\sum_{n_H =s}^{N_H -1}
\MC{S} \SB {
   \sum_{n_H' =0}^{N_H -1}
   B \SB {\psi \SB {\f, n_H'}}
   \V {u}_{n_H'}
}
\DB {n_H} ^2 \NR[+]
}
Note that \m {\Nm {B \SB {\psi'}}} is strictly decreasing in \m {\SB {0,\pi}}.
We seek to bound the ``rectangulars'' with an integral, and we have to split the cases that \m {N_H} is odd and even.
Anyway, a moment's reflection shows
\Disp {
\NC R^2
\leq \NC \F {1}{N_H^2} \D \F {N_H}{2\pi} \D 2 \int_{\pi s/N_H}^{\pi} B \SB {\psi'} ^2 d \psi' \NR
\NC = \NC \F {2304} {N_H \pi^6}
\int _{s /N_H} ^1 \F{1} {(24/\pi^2 -x'^2)^2 x'^2} dx' \NR
\NC =\NC \F{1} {2\pi^2}
\RB {
  -\F {8} {u}
+\F {4\pi^2 u} {24 -\pi^2 u^2}
+\R{6} \pi \tanh^{-1} \SB {\F {\pi u} {2\R{6}}}
}
\Bigg \| _{s/N_H} ^1 \NR
\NC \leq \NC \F {4} {\pi^2} \D \F {1} {s} +0.032670 \NR[+]
}
In the last step we bound the lower limit of the second and third term with \m {x' =0}, and leave the dominating \m {1/x'}.

In summary,

\Result
{Lemma}
{
Let \m {\f} be given, and array response \m {\V {a} \SB {\f}} defined as in ().
Then \m {\V {a} \SB {\f}} is almost-\m {s}-sparse according to the \m {\ell_2}-norm with remainder \m {R} to be
\Disp {
\NC R
= \NC \F {2} {\pi} \D \F {1} {\R{s}} +\F {1} {62}. \NR[+]
}
}


\stoptext

\Result
{Lemma (Tentative)}
{
Let \m {\f} and \m {\th} be uniformly, independently distributed in \m {[0,2\pi)}, and linear array response \m {\V {a}} defined as in ().
Let \m {\V {g}} be defined as above.
Then \m {\V {g}} is almost-\m {L}-sparse with \m {\ell_1}-residue \m {R\SB {N_H, L}} to be
\Disp {
\NC R
\leq \NC \F {L}{\pi^2} \RB { \log \F {N_H}{L} }^2 \NR
}
}

\startsection [title={Concentration Inequality of \m {\M{F}_B, \M{W}_B}}]

\Result
{Definition}
{
Let \m {P} be fixed.
For \m {\MC {T}, \MC {T}' \subset T \RB {N_p}}, define the \m {s, s'}-restricted orthogonality constant \m {\tau_{s,s'} \SB {P} >0} to be the smallest number such that
\Disp {
\NC \Nm {\IP {P_{\MC {T}} h, P_{\MC {T}'} h'}}
\leq \NC \tau_{s, s'} \SB {P} \cdot \VNm {h} _2 \VNm {h'} _2 \NR
}
}

From ``Decoding from Linear Programming'' (Cand\`es and Tao 2005), Lemma 1.1:

\Result
{Lemma}
{
Let \m {\M{P}} be fixed.
Then \m {\tau_{s, s'} \SB {\M{P}}} is bounded in both direction as follows,
\Disp {
\NC \d_{s+s'} \SB {\M{P}} -\max \SB {\CB {\d_s \SB {\M{P}}, \d_{s'} \SB {\M{P}} }}
\leq \NC \tau_{s, s'} \SB {\M{P}} \NR
\NC \leq \NC \d_{s+s'} \SB {\M{P}} \NR[+]
}
}

Thus \m {\d_s \SB {\M{P}}}, which defines how much the deformation of norm is, also tells us how much the inner product is deformed.
We may well keep track of \m {\d_s \SB {\M{P}}} only.
When \m {\SB {\M{P}}} is clear, we may suppress it.

We seek to find \m {\d_s \SB {\M{F}_B} \SB {\o_t}}, along similar lines with Achlioptas (2001) and Baraniuk et.\ al.\ (2008).
Try to set each entry of \m {\M{F}_B} to be i.i.d.\ Gaussian r.v.\ with mean 0, standard deviation \m {1/2}, multiplied by a normalizing constant \m {\a >0}.
They are (with a slight of abuse of meaning of \m {\o_t} and so on)
\Disp{
\NC d \o_t
=\NC \F {1} {\R {\pi} \a} \exp
  \RB {-\F{1}{\a^2} \MF{Re} \SB {\M{F}_B \DB {n_R, n_Y} \SB {\o_t}} ^2}
d \MF{Re} \SB {\M{F}_B \DB {n_R, n_Y}} \NR[+]
\NC d \o_t
=\NC \F {1} {\R {\pi} \a} \exp
  \RB {-\F{1}{\a^2} \MF{Im} \SB {\M{F}_B \DB {n_R, n_Y} \SB {\o_t}} ^2}
d \MF{Im} \SB {\M{F}_B \DB {n_R, n_Y}} \NR[+]
\NC n_R
= \NC 0, 1, 2, \dots, N_R -1 \NR
\NC n_Y
= \NC 0, 1, 2, \dots, N_Y -1 \NR
}
We know that the magnitude \m {\M{F}_B \DB {n_R, n_Y}} follows Rayleigh distribution, having
\Disp{
\NC \NC \MB{E} _{\o_t} \SB {\Nm {\M{F}_B \DB {n_R, n_Y} \SB {\o_t}}} \NR
\NC =\NC \F{\R{\pi}}{2} \a \NR[+]
\NC M_2
:=\NC \MB{E} _{\o_t} \SB {\Nm {\M{F}_B \DB {n_R, n_Y} \SB {\o_t}}^2} \NR
\NC =\NC \a^2 \NR[+]
\NC M_4
:=\NC \MB{E} _{\o_t} \SB {\Nm {\M{F}_B \DB {n_R, n_Y} \SB {\o_t}}^4} \NR
\NC =\NC 2 \a^4 \NR[+]
}
Fix any test vector \m {\V{u} \in \MB{V}_\MB{C} \SB{N_Y}}, we have to study the concentration of \m {\VNm {\M{F}_B \V{u}}_2} in probability mass.
We shall exploit Chebyshev bound, which required the first and second moment to be found.
\Disp{
\NC \NC \MB{E} _{\o_t} \SB {\VNm {\M{F}_B \SB {\o_t} \V{u}} _2 ^2} \NR
\NC = \NC \MB{E} \SB {
  \sum_{n_R=0}^{N_R-1}
  \Nm {\sum_{n_Y=0}^{N_Y-1} \M{F}_B \DB {n_R, n_Y} ^* \V{u} \DB{n_Y}} ^2
} \NR
\NC = \NC \sum_{n_R=0}^{N_R-1}
  \MB{E} \SB {\Nm {\sum_{n_Y=0}^{N_Y-1} \M{F}_B \DB {n_R, n_Y} ^* \V{u} \DB{n_Y}} ^2}
\NR
\NC = \NC
\sum_{n_R=0}^{N_R-1}
  \MB{E} \SB {
     2 \sum_{\startsubstack n_Y, n_Y'=0 \NR n_Y <n_Y' \stopsubstack}^{N_Y-1}
       \MF {Re} \SB{
         \M{F}_B \DB {n_R, n_Y} ^* \M{F}_B \DB {n_R, n_Y'}
         \V{u} \DB{n_Y} \V{u} \DB{n_Y'} ^*
       }
   } \NR
\NC \NC \quad \quad +\sum_{n_R=0}^{N_R-1}
  \MB{E}
     \SB {\sum_{n_Y=0}^{N_Y-1} \Nm {\M{F}_B \DB {n_R, n_Y}}^2 \Nm {\V{u} \DB{n_Y}}^2}
\NR
\NC = \NC
2 \sum_{n_R=0}^{N_R-1}
\sum_{\startsubstack n_Y, n_Y'=0 \NR n_Y <n_Y' \stopsubstack}^{N_Y-1}
\MF {Re} \SB{
   \MB{E} \SB {\M{F}_B \DB {n_R, n_Y}^*}
   \MB{E} \SB {\M{F}_B \DB {n_R, n_Y'}}
}
\V{u} \DB{n_Y} \V{u} \DB{n_Y'} ^*
\NR
\NC \NC \quad \quad +\sum_{n_R=0}^{N_R-1}
   \sum_{n_Y=0}^{N_Y-1} \MB{E} \SB {\Nm {\M{F}_B \DB {n_R, n_Y}}^2} \Nm {\V{u} \DB{n_Y}}^2
\NR
\NC = \NC \a^2 N_R \VNm {\V{u}} _2 ^2 \NR[+]
}
Thus, we may set
\Disp{
\NC \a
=\NC \F {1} {\R{N_R}} \NR[+]
}
To make
\Disp{
\NC \MB{E} _{\o_t} \SB {\VNm {\M{F}_B \SB {\o_t} \V{u}} _2 ^2}
=\NC \VNm {\V{u}} _2 ^2
}

Similarly, we have to find, in advance, the second moment.
\Disp{
\NC \MB{E} \SB {\VNm {\M{F}_B \V{u}} _2 ^4}
=\NC \MB{E} \SB {
  \RB {
    \sum_{n_R=0}^{N_R-1}
    \Nm {\sum_{n_Y=0}^{N_Y-1} \M{F}_B \DB {n_R, n_Y} ^* \V{u} \DB{n_Y}} ^2
  } ^2
}
\NR[+]
}
Without spelling out everything, we notice that as long as a term has a single \m {\M{F}_B \DB {n_R, n_Y}} factor, it's expectation is zero.
Also notice that
\Disp{
\NC \NC \MB{E} \SB {\M{F}_B \DB {n_R, n_Y}^2} \NR
\NC = \NC \MB{E} \SB {\MF {Re} \SB {\M{F}_B \DB {n_R, n_Y}}^2}
   -\MB{E} \SB {\MF {Im} \SB {\M{F}_B \DB {n_R, n_Y}}^2} \NR
\NC \NC \quad \quad +2 \Ss {i} \MB{E} \SB {\MF {Re} \SB {\M{F}_B \DB {n_R, n_Y}}}
      \MB{E} \SB {\MF {Im} \SB {\M{F}_B \DB {n_R, n_Y}}} \NR
\NC = \NC 0 \NR[+]
}
Having said that, with straightforward calculation, we see that the remaining terms are
\Disp{
\NC \NC \MB{E} \SB {\VNm {\M{F}_B \V{u}} _2 ^4} \NR
\NC = \NC
\sum_{n_R=0}^{N_R-1} \sum_{n_Y=0}^{N_Y-1}
\Nm {\M{F}_B \DB {n_R, n_Y}} ^4
\Nm {\V{u} \DB{n_Y}} ^4 \NR
\NC \NC \quad \quad
+\sum _{\startsubstack n_R, n_R' =0 \NR n_R <n_R' \stopsubstack}^{N_R-1}
\sum _{n_Y =0}^{N_Y-1}
\Nm {\M{F}_B \DB {n_R, n_Y}} ^2
\Nm {\M{F}_B \DB {n_R', n_Y'}} ^2
\Nm {\V{u} \DB{n_Y}} ^2
\Nm {\V{u} \DB{n_Y'}} ^2 \NR
\NC \NC \quad \quad
+\sum _{n_R, n_R' =0}^{N_R-1}
\sum _{\startsubstack n_Y, n_Y' =0 \NR n_Y <n_Y' \stopsubstack}^{N_Y-1}
\Nm {\M{F}_B \DB {n_R, n_Y}} ^2
\Nm {\M{F}_B \DB {n_R', n_Y'}} ^2
\Nm {\V{u} \DB{n_Y}} ^2
\Nm {\V{u} \DB{n_Y'}} ^2 \NR
\NC \NC \quad \quad
+\sum _{n_R =0}^{N_R-1}
\sum _{\startsubstack n_Y, n_Y' =0 \NR n_Y <n_Y' \stopsubstack}^{N_Y-1}
\Nm {\M{F}_B \DB {n_R, n_Y}} ^2
\Nm {\M{F}_B \DB {n_R, n_Y'}} ^2
\Nm {\V{u} \DB{n_Y}} ^2
\Nm {\V{u} \DB{n_Y'}} ^2 \NR
\NC =\NC N_R \D M_4 \D \VNm {\V{u}} _4 ^4
   +\F {1} {2} N_R \RB {N_R-1} \D M_2^2 \D \RB {\VNm {\V{u}} _2 ^4 -\VNm {\V{u}} _4 ^4} \NR
\NC \NC \quad \quad + N_R^2 \D M_2^2 \D \RB {\VNm {\V{u}} _2 ^4 -\VNm {\V{u}} _4 ^4}
   + N_R \D M_2^2 \D \RB {\VNm {\V{u}} _2 ^4 -\VNm {\V{u}} _4 ^4} \NR
\NC =\NC \RB {N_R M_4 -\F{1}{2} \RB {3N_R^2 +N_R} M_2^2} \VNm {\V{u}} _4 ^4
+\F{1}{2} \RB {3N_R^2 +N_R} M_2^2 \VNm {\V{u}} _2 ^4 \NR[+]
}
Plugging in the moments, we have
\Disp{
\NC =\NC -\F{3}{2} \RB {1 -\F{1}{N_R}} \VNm {\V{u}} _4 ^4
+\F{1}{2} \RB {3 +\F{1}{N_R}} \VNm {\V{u}} _2 ^4 \NR[+]
}
Use \m {\VNm {\V{u}} _2 \leq N_y \VNm {\V{u}} _4} and drop the rest of \m {\VNm {\V{u}} _4 ^4} term, and we have simply
\Disp{
\NC \NC \leq \F{3}{2} \VNm {\V{u}} _2 ^4 \NR[+]
}

In conclusion,
\Disp{
\NC \Ss{Var} _{\o_t} \SB {\VNm {\M{F}_B \SB {\o_t} \V{u}} _2 ^2}
\leq \NC \F{1}{2} \VNm {\V{u}} _2 ^4 \NR[+]
}
Thus, by Chebyshev bound,
\Result
{Lemma}
{
Let \m {\M{F}_B \in \MB {M}_{\MB {C}} \SB {N_R, N_Y}} be generated randomly according to ().
Then, for any fixed \m {\V{u} \in \MB {V}_{\MB {C}} \SB {N_Y}}, and for any \m {\e >0},
\Disp{
\NC \MB{P} _{\o_t}
\SB {
  \Nm {\VNm {\M{F}_B \V{u}} _2 ^2 -\VNm {\V{u}} _2 ^2}
  \geq \e \VNm {\V{u}} _2 ^2
}
\leq \NC \F {1} {2\e^2} \NR[+]
}
}
According to Lemma 5.1 in Baraniuk et.\ al.\ (2008), substitution of relevent quantities yields
\Result
{Lemma}
{
Let \m {\M{F}_B ^\Tr} be found as above.
Suppose the probability that RIP holds for \m {\M{F}_B} w.r.t.\ \m {\d_s} is \m {P}, then
\Disp{
\NC 1 -P
\leq \NC 4 \D 12^s \D \d_s^{-\RB {s+2}} \NR[+]
}
Same can be said of \m {\M{W}_B}.
}

\stopsection

\startsection [title={Concentration Inequality of Precoders and Combiners}]

Let \m {\M{F}_R \DB {n_H, n_R}} be uniformly distributed on the unit circle on the complex plane, which gives probability density
\Disp{
\NC d \o_t
= \NC \F {1} {\pi} \RB {1 -\RB {\MF{Re} \SB {\M{F}_R \DB {n_H, n_R} \SB {\o_t}}} ^2}^{-1/2}
d \MF{Re} \SB {\M{F}_R \DB {n_H, n_R}} \NR[+]
\NC d \o_t
= \NC \F {1} {\pi} \RB {1 -\RB {\MF{Im} \SB {\M{F}_R \DB {n_H, n_R} \SB {\o_t}}} ^2}^{-1/2}
d \MF{Im} \SB {\M{F}_R \DB {n_H, n_R}} \NR[+]
}
As a result,
\Disp{
\NC \NC \MB{E} _{\o_t} \SB {\M{F}_R \DB {n_H, n_R} \SB {\o_t}} \NR
\NC =\NC \a \NR[+]
\NC M_2
:=\NC \MB{E} _{\o_t} \SB {\Nm {\M{F}_R \DB {n_H, n_R} \SB {\o_t}}^2} \NR
\NC =\NC \a^2 \NR[+]
\NC M_4
:=\NC \MB{E} _{\o_t} \SB {\Nm {\M{F}_R \DB {n_H, n_R} \SB {\o_t}}^4} \NR
\NC =\NC \a^4 \NR[+]
}

Fix any test vector \m {\V{u} \in \MB{V}_\MB{C} \SB{N_H}}, 
By a similar argument, we may set
\Disp{
\NC \a
=\NC \F {1} {\R{N_H}} \NR[+]
}
to make
\Disp{
\NC \NC \MB{E} _{\o_t} \SB {\VNm {\M{F}_R \SB {\o_t} \V{u}} _2 ^2} \NR
\NC = \NC \VNm {\V{u}} _2 ^2 \NR[+]
}
Furthermore, if we plug in the moments and use \m {\VNm {\V{u}} _2 \leq N_y \VNm {\V{u}} _4} and drop the rest of \m {\VNm {\V{u}} _4 ^4} term, we have simply
\Disp{
\NC \NC \MB{E} \SB {\VNm {\M{F}_R \V{u}} _2 ^4} \NR
\NC =\NC \RB {N_H M_4 -\F{1}{2} \RB {3N_H^2 +N_H} M_2^2} \VNm {\V{u}} _4 ^4
+\F{1}{2} \RB {3N_H^2 +N_H} M_2^2 \VNm {\V{u}} _2 ^4 \NR
\NC =\NC -\F{1}{2} \RB {3 -\F{1}{N_H}} \VNm {\V{u}} _4 ^4
+\F{1}{2} \RB {3 +\F{1}{N_H}} \VNm {\V{u}} _2 ^4 \NR
\NC \leq \NC \F{3}{2} \VNm {\V{u}} _2 ^4 \NR[+]
}

In conclusion,
\Disp{
\NC \Ss{Var} _{\o_t} \SB {\VNm {\M{F}_R \SB {\o_t} \V{u}} _2 ^2}
\leq \NC \F{1}{2} \VNm {\V{u}} _2 ^4 \NR[+]
}

\stopsection

\startsection [title={RIP of Precoders and Combiners}]

The relevent expressions for \m {\M{F}_B ^\Tr} and \m {\M{F}_R ^\Tr} are identical, and same can be said of \m {\M{W}_B} and \m {\M{W}_R}.
Let \m {\Phi} be either of \m {\M{R}_B ^\Tr}, \m {\M{R}_R ^\Tr}, \m {\M{W}_B}, or \m {\M{W}_B}.
By Chebyshev bound, we obtain an identical expression,
\Result
{Lemma}
{
Let \m {\Phi} be generated randomly as above.
Then, for any fixed complex \m {\V{u}} (with corresponding dimension), and for any \m {\e >0},
\Disp{
\NC \MB{P} _{\o_t}
\SB {
  \Nm {\VNm {\Phi \V{u}} _2 ^2 -\VNm {\V{u}} _2 ^2}
  \geq \e \VNm {\V{u}} _2 ^2
}
\leq \NC \F {1} {2\e^2} \NR[+]
}
}
According to Lemma 5.1 in Baraniuk et.\ al.\ (2008), substitution of relevent quantities yields
\Result
{Lemma}
{
Suppose the probability that RIP holds for \m {\Phi} w.r.t.\ \m {\d_s} is \m {P}, then
\Disp{
\NC 1 -P
\leq \NC 4 \D 12^s \D \d_s^{-\RB {s+2}} \NR[+]
}
Same can be said of \m {\M{W}_B}.
}

We may bound \m {\RB {1 +\d_s}^2} by \m {1 +3\d_s}.
A moment of reflection shows that 


\stopsection

\startsection [title={Expected Square Error for Complex-Case DS}]

The rest follows ``The Dantzig Selector'' very closely.
The generalization to complex vector is necessary in our setting.
We spell out the proof when such generalization is nontrivial.

\Result
{Proposition}
{
Let \m {\V {g}} and \m {\V {d}} be defined as above.
Then
\Disp {
\NC \VNm {\V {d}_{\MC {C}}} _1
\leq \NC \VNm {\V {d}_{\MC {A}}} _1 +2\VNm {\V {g}_{\MC {C}}} _1 \NR
}
}

To show this, observe that with triangle inequality applied respectively on \m {\MC {A}} and \m {\MC {C}},
\Disp {
\NC \VNm {\V {g}} _1
-\VNm {\V {d}_{\MC {A}}} _1
+\VNm {\V {d}_{\MC {C}}} _1
-\VNm {\V {g}_{\MC {C}}} _1
\leq \NC \VNm {\V {g} +\V {d}} _1 \NR
}
In the first line, we recall \m {\V {g} =\V {g}_{\MC {A}}}.
On the other hand, by construction that \m {\hat {g}} minimizes the \m {\ell_1}-norm,
\Disp {
\NC \VNm {\V {g} +\V {d}} _1
=\NC \VNm {\hat {\V {g}}} _1 \NR
\NC \leq \NC \VNm {\V {g}} _1 \NR
}
The result follows by combining.

\Result
{Lemma}
{
Let \m {\V {z}} and \m {\M {P}} be defined as above.
Then
\Disp {
\NC \Nm {\IP { \V {z}, \M {P} \DB {:, n_g} }}
\leq \NC  2 \R {\log N_h},
\quad n_g 
=1, \dots, N_h. \NR
}
with overwhelming probability.
}

This only depends on the fact that \m {\M {P} \DB {:, n_g}} has unity \m {\ell_2}-norm, and on the randomness of \m {\V {z}}.

Recall the following bound for \m {Q} function
\Disp {
\NC Q\SB {x}
\leq \NC \F {1}{2} \Ss {e}^{-x^2/2} \NR
}
Particularly, for \m {x =\R {2 \log N_h}}, according to CLT,
\Disp {
\NC Q\SB {\R {2 \log N_h}}
=\NC \F {1}{N_h}. \NR
}

\color[red]{(To be done)}

\Result
{Lemma}
{
Let \m {\V {d}} and \m {\M {P}} be defined as above, and \m {\M {P}} satisfies RIP as in ().
\Disp {
\NC \VNm {\M {P}^\Adj \M {P} \V {d}} _\infty
\leq \NC  4 \R {\log N_h},
\quad n_g 
=1, \dots, N_h. \NR
}
}

To show this, by definition
\Disp {
\NC \IP { \V {z} -\RB {\V {y} -\M {P} \hat {\V {g}}}, \M {P} \DB {:,n_y} }
= \NC \IP { \M {P} \hat {\V {g}} -\M {P} \V {g}, \M {P} \DB {:,n_y} } \NR
\NC = \NC \IP { \M {P} \V {d}, \M {P} \DB {:,n_y} } \NR
}

By construction
\Disp {
\NC \VNm { \M {P} \DB {:,n_y}^\Adj \RB {\V {y} -\M {P} \hat {\V {g}}} } 
\leq \NC \VNm { \M {P}^\Adj \RB {\V {y} -\M {P} \hat {\V {g}}} } _\infty \NR
\NC \leq \NC 2\R {\log N_h} \NR
}
By triangle inequality, together with Lemma (), we have
\Disp {
\NC \VNm {\M {P} \DB {:,n_y}^\Adj \M {P} \V {d}} 
\leq \NC \VNm {\IP { \V {z}, \M {P} \DB {:,n_y} }}  +\IP { \V {y} -\M {P} \hat {\V {g}}, \M {P} \DB {:,n_y} } \NR
\NC \leq \NC 2 \R {\log N_h} +2 \R {\log N_h} \NR
}
which implies
\Disp {
\NC \VNm {\M {P}^\Adj \M {P} \V {d}} _\infty
\leq \NC 4 \R {\log N_h}. \NR
}

From ``Dantzig Selector'' (Cand\`es and Tao 2007), Lemma 1, first equation, we have the result as below.
The original result is for real vector spaces, but we have checked that the proof is completely valid in complex vector spaces.
Of course the interpretation of modulus and the inner product changes accordingly.

\Result
{Lemma}
{
Let \m {\V {d}} and \m {\M {P}} be defined as above, and \m {\M {P}} satisfies RIP as in () with respect to \m {\d_s}.
\Disp {
\NC \VNm {\V {d}_{\MC {AB}}} _2
\leq \NC \F {1}{1-\d_{2s}} \VNm {P_{\MC {A} \MC {B}}^\Tr P d} _2 +\F {\d_{3s}}{\RB {1-\d_{2s}} \R {s}} \VNm {d_{C}} _1 \NR
}
}

From ``Dantzig Selector'' (Cand\`es and Tao 2007), Lemma 1, second equation, we have the result as below.
Again, their proof works with complex vector spaces in place of real ones too.

\Result
{Lemma}
{
Let \m {\V {d}} be defined as above.
Then
\Disp {
\NC \VNm {\V {d}} _2^2
\leq \NC \VNm {\V {d}_{\MC {A} \MC {B}}} _2^2 +\F {1}{s} \VNm {\V {d}_{\MC {C}}} _1^2 \NR
}
}

\startsection [title={The Main Bound}]

We can now formulate and prove the main bound of ours.
Here, we use \m {s=L} as the sparsity threshold.

\Result
{Theorem}
{
Let \m {\V {y}}, \m {\M {P}}, \m {\V {g}}, \m {\hat {\V {g}}}, \m {\V {d}} be defined as above.
Then
\Disp {
\NC \VNm {\V {d}} _2
\leq \NC \F {4}{\pi^4} \d_{3L}^4 \RB {1-2\d_{2L}} L^4 \RB { \log N_H}^4 \NR
}
with overwhelming probability.
}

We are ready to combine previous lemmata.
The first quantity we want to bound away is
\Disp {
\NC \VNm {\M {P}_{\MC {A} \MC {B}}^\Tr \M {P} \V {d}} _2
\leq \NC \VNm {\M {P}^\Tr \M {P} \V {d}} _2 \NR
\NC \leq \NC \R {N_h} \VNm {\M {P}^\Tr \M {P} \V {d}} _\infty \NR
\NC \leq \NC 4 \R {N_h \log N_h} \NR
}
Thus, by virtue of Lemma (),
\Disp {
\NC \VNm { \V {d}_{A} } _1
\leq \NC \R {L} \VNm { \V {d}_{A} } _2 \NR
\NC \leq \NC \R {L} \VNm { \V {d}_{\MC {AB}} } _2 \NR
\NC \leq \NC \F {\d_{3L}} {1-\d_{2L}} \VNm { \V {d}_{\MC {C}} } _1 +\F {4} {1-\d_{2L}} \R {L N_h \log N_h} \NR
}

As the next step, we must eliminate \m {\VNm {d_{\MC {A}}} _1} in rhs of Lemma ().
\Disp {
\NC \VNm { \V {d}_{\MC {C}} } _1
\leq \NC \VNm { \V {d}_{\MC {A}} } _1 +2 \VNm { \V {g}_{\MC {C}} } _1 \NR
\NC \leq \NC \F {\d_{3L}} {1-\d_{2L}} \VNm { \V {d}_{\MC {C}} } _1
+2 \VNm { \V {g}_{\MC {C}} } _1
+\F {4} {1-\d_{2L}} \R {L N_h \log N_h} \NR
}
Or,
\Disp {
\NC \VNm { \V {d}_{\MC {C}} } _1
\leq \NC 2 \F {1-\d_{2L}} {1 -\d_{2L} -\d_{3L}} \VNm { \V {g}_{\MC {C}} } _1
+\F {4} {1-\d_{2L} -\d_{3L}} \R {L N_h \log N_h} \NR
}

We are ready to bound \m {\VNm {d} _2^2}.
Using Lemma () again, we have
\Disp {
\NC \VNm { \V {d} } _2^2
\leq \NC \VNm {\V {d}_{\MC {A} \MC {B}}} _2^2 +\F {1}{L} \VNm {\V {d}_{\MC {C}}} _1^2 \NR
\NC \leq \NC  \RB { \F {\d_{3L}^2} {L^2 \RB {1-\d_{2L}}^2} +\F {1}{L} } \VNm {\V {d}_{\MC {C}}} _1^2
+\F {8 \d_{3L}} {L \RB {1-\d_{2L}}^2} \R {N_h \log N_h} \VNm {\V {d}_{\MC {C}}} _1 \NR
\NC \NC \quad +\F {16}{\RB {1-\d_{2L}}^2} N_h \log N_h \NR
}
Finally, plug in the bound for \m {\VNm {\V {d}_{\MC {C}}} _1}, the last unknown, and we make use of the almost-sparsity condition of \m {\VNm {\V {d}_{\MC {C}}} _1}.
There are several dozens of terms if we expand all.
but for simplicity, we keep only the leading term under the approximation
\Disp {
\NC 1 \ll \NC L \NR
\NC \ll \NC N_h \NR
}
And expand to the first order expressions containing \m {\d_{2L}} or \m {\d_{3L}} in the denominator using
\Disp {
\NC \d_{2L} <\NC \d_{3L} \ll 1. \NR
}
Then
\Disp {
\NC \VNm {\V {d}} _2^2
\leq \NC \F {4}{\pi^4} \d_{3L}^4 \RB {1-2\d_{2L}} L^4 \RB { \log N_H}^4 \NR
}

\color[red]{(To be done)}

\stopchapter
