\input {./preamble.tex}

\starttext

\input {./1_slide.tex}
\input {./2_slide.tex}
\input {./3_slide.tex}
\input {./4_slide.tex}
\input {./5_slide.tex}

\stoptext

\page [yes] % % % % % % % % % % % % % % % % % % % % % % % % % %


\Frametitle {Program: The Dantzig Selector}
Let \m {} and \m {} be given, and \m {} be fixed.
Find \m {} with
\Disp{
\hat{\V{h}} =\min_{\V{h}'} \quad &\|\V{h}'\|_1 \\ \NT
\RM{subject}\; \RM{to} \quad &\|\M{P}^\H (\M{P} \V{h'} -\V{y})\|_\infty \leq \gamma
}



\page [yes] % % % % % % % % % % % % % % % % % % % % % % % % % %


\Frametitle {Performance Guarantee of DS}


\I Now, consider a linear transformation with noise corruption,
\Disp{
\V{y} =\M{P} \V{h} + \V{z}
}
where \m {} is i.i.d.\ standard Gaussian.

\I They showed that the mean square error \m {} is bounded with overwhelming probability.

\I Furthermore, this \m {}-minimization problem with \m {}-constraint may be recast as a linear program (LP), lending convex programming technique applicable.





\page [yes] % % % % % % % % % % % % % % % % % % % % % % % % % %


\Frametitle {Definition: Restricted Isometry Property}


\I Consider \m {}, with unity-\m {}-norm columns.
For \m {}, we say that \m {} satisfies the restricted isometry property (RIP) of sparsity \m {} with respect to \m {}, if, for all \m {}-sparse \m {}, for all \m {} with \m {},
%
\Disp{
(1-\d_s) \|\V{x}\|^2
\leq \|P_{\MC{T}} \V{x}\|_2^2
\leq (1+\d_s) \|\V{x}\|_2^2
}
\I RIP is essentially saying that \m {} is ``almost unitary'' up to ``relative error'' \m {}.





\page [yes] % % % % % % % % % % % % % % % % % % % % % % % % % %


\Frametitle {Orthogonal Matching Pursuit}


\I Afterwards, scholars (Tropp and Gilbert 2007b) proposed a greedy algorithm called Orthogonal Matching Pursuit (OMP)
\I Here, we pick up the columns of the sensing matrix \m {} greedily, hoping to correspond to the support of \m {}, thus recovering the original signal.
\I An i.i.d.\ random sensing matrix may perform sufficiently well, and may even recover the original signal in an overwhemingly probability too.





\page [yes] % % % % % % % % % % % % % % % % % % % % % % % % % %


\Frametitle {Recent Literature on Compressive Channel Sensing}


\I Scholars has since favored OMP rather than DS, let alone other sparse algorithm, without clear justification
\I Previous work simply assumes the norm of the channel matrix is bounded in some way, and dependency on the sparsity of the channel parameters is unknown
\I OMP's requirement on the sensing matrix (elementwise i.i.d.\ Gaussian) seems to be more restrictive than DS's (RIP)
\I The quantization of angle in generating may be a problem, and that is difficult to analyze in OMP's setting





\page [yes] % % % % % % % % % % % % % % % % % % % % % % % % % %


\Frametitle {Our Work}


\I We will use a modified DS rather than OMP, done on the beamspace rather than the spatial domain, and involving complex numbers rather than real numbers.
\I We will show an explicit bound, where the sparsity of the virtual channel matrix is depends explicitly on the number of paths of the channel.
\I Bounding the beamspace sparsity, accordingly the concern of quantization error of the virtual channel's phase angle has been incorporated in our proof of the bound.
\I We will derive explicitly the SOCP problem and afterwards its dual problem, and wrote a proof-of-concept but efficient code.





\page [yes] % % % % % % % % % % % % % % % % % % % % % % % % % %


\Frametitle {Channel Model}


\I The response of uniform linear array is
\Disp{
\V{a} (\psi')
=\F{1}{\R{N_H}} \sum_{n=1}^{N} \RM{e}^{n \psi' i} \V{u}_n
\in \MB{V}_\MB{C} (N_H)
}
\I Let the virtual angle of departure and arrival be defined as thus to simplify expression
\Disp{
\f_l =\dfrac{d_{\RM{arr}}} {\lambda} \sin \f_l', \quad \th_l =\dfrac{d_{\RM{arr}}} {\lambda} \sin \th_l'
}
\I Let there be \m {} paths.
The channel matrix is, then,
\Disp{
H
=\sum_{l=0}^L \alpha_l \V{a} (\f_l) \V{a} (\th_l)^\H
\in \MB{M}_\MB{C} (N_H, N_H)
}





\page [yes] % % % % % % % % % % % % % % % % % % % % % % % % % %


\Frametitle {Precoder Setting}


\I We consider the hybrid configuration at both transmitter and receiver end.
In the transmitter end, there are digital precoder \m {} and analog precoder \m {}.
In the receiver end, there are digital combiner \m {} and analog combiner \m {}.
\Disp{
\M{F}_B \in &\MB{M}_{\MB{C}} (N_R, N_Y) \\
\M{F}_R \in &\MB{M}_{\MB{C}} (N_H, N_R) \\
\M{W}_R \in &\MB{M}_{\MB{C}} (N_R, N_H) \\
\M{W}_B \in &\MB{M}_{\MB{C}} (N_Y, N_R)
}
\I Recall the constraint of magnitude for analog precoders:
\Disp{
|\M{F}_R (n_h, n_r)| =1, \quad |\M{W}_R (n_r, n_h)| =1, \\
n_h =1, \dotsc N_H, \quad n_r =1, \dotsc N_R \NT
}
\I We also assume
\Disp{
N_Y \ll N_R \ll N_H
}





\page [yes] % % % % % % % % % % % % % % % % % % % % % % % % % %


\Frametitle {Effective Channel}


\I We have the effective channel \m {}
\I We may estimate \m {} with \m {}, \m {}, using pilog signal as unit vectors \m {}.
\I It remains to recover \m {} with knowledge of \m {}, while \m {}, \m {}, \m {}, and \m {} are in our control






\page [yes] % % % % % % % % % % % % % % % % % % % % % % % % % %


\Frametitle {Vectorization}
Previous literature usually approaches the problem as
\Disp{
\V{h}
:= &\RM{vec} (\M{H})
\in \MB{V}_{\MB{C}} (N_g) \\
\V{y}
:= &\RM{vec} (\M{Y})
\in \MB{V}_{\MB{C}} (N_y) \\
\V{z}^\star
:= &\RM{vec} (\M{Z})
\in \MB{V}_{\MB{C}} (N_y) \\
\M{P}^\star
:= &(\M{F}_R^\Tr \M{F}_B^\Tr) \otimes (\M{W}_B \M{W}_R)
\in \MB{M}_{\MB{C}} (N_y, N_g).
}
and for short we set \m {} and \m {},
so that
\Disp{
\V{y} =\M{P}^\star \V{h} +\V{z}^\star
}



\page [yes] % % % % % % % % % % % % % % % % % % % % % % % % % %


\Frametitle {Beamspace Channel Representation}
Let \m {} be the DFT matrix.
If we write \m {}, i.e.\ the beamspace (i.e., spatial frequency domain) representation of \m {}, then
\Disp{
\M{Y}
:=&\M{W}_B \M{W}_R \M{K} ( \M{G} \M{K}^\H \M{F}_R \M{F}_B +\M{K}^\H \M{Z} )
\in \MB{M}_{\MB{C}} (N_Y, N_Y) \\
\M{P}
:=&(\M{F}_B^\Tr \M{F}_R^\Tr \M{K}^\ast) \otimes (\M{W}_B \M{W}_R \M{K})
\in \MB{M}_{\MB{C}} (N_y, N_g)
}
where accordingly
\Disp{
\V{g} := &\RM{vec} (\M{G}) \in \MB{M}_{\MB{C}} (N_g) \\
\V{z} := &\RM{vec} (\M{K}^\H \M{Z}) \in \MB{V}_{\MB{C}} (N_y)
}
so that
\Disp{
\V{y}
=\M{P} \V{g} +\V{z}
}



\page [yes] % % % % % % % % % % % % % % % % % % % % % % % % % %


\Frametitle {Proposed Program}


\I Let \m {} be given.
Then, with parameter \m {} specified, find
%
\Disp{
\hat{\V{g}}
=\min_{\V{g}'} &\|\V{g}'\|_1 \quad \\
\RM{subject}\; \RM{to}\quad
&\|\M{P}^\H (\V{y} -\M{P} \V{g}')\|_\infty \leq \gamma
}
\I And convert \m {} back to matrix form as
\Disp{
\hat{G} =\RM{vec}^{-1} (\hat{g})
}
\I And finally recover the estimated \m {} in the space domain as
\Disp{
\hat{\M{H}} =\M{K} \hat{\M{G}} \M{K}^\H.
}





\page [yes] % % % % % % % % % % % % % % % % % % % % % % % % % %


\Frametitle {Lemma: \m {} is Almost Sparse}
For arbitrary \m {}, for \m {}, \m {} is almost-\m {}-sparse with \m {}-residue \m {} to be
\Disp{
R
   \leq \F{1}{\pi} \log \F{N_H}{L}.
}



\page [yes] % % % % % % % % % % % % % % % % % % % % % % % % % %


\Frametitle {Proof (1/3)}
\Disp{
D (\f')
:=&\left| \sum_{n=0}^{N_H-1} \RM{e}^{i n \f'} \right|
=\F{|\sin (N_H \f'/2)|}{|\sin (\f' /2)|} \\
\left| x -\F{x^3}{6} \right|
\leq &\sin x, \quad -\pi \leq x \leq \pi \\
\left| D (\f') \right|
= &\F{48}{|\f'^2 -24| |\f'|}
}


\I Definition and arrangement
\I Can be shown with basic calculus
\I Plug the previous eqn.\ into \m {}





\page [yes] % % % % % % % % % % % % % % % % % % % % % % % % % %


\Frametitle {Proof (2/3)}
\Disp{
\M{K}^\H \V{a}(\f) (k)
=&\F{1}{N_H} D \left( \f -\F{2 \pi k} {N_H} \right) \\
R(\eta)
:=&\F{1}{N_H} \sum_{n_H =s}^{N_H -1} D \left( \eta +\F{2 \pi n_H} {N_H} \right) \\
R(\eta) -\F{2\pi} {N_H}
\leq &\F{1}{N_H} N_H \int_{\f'=2\pi L/N_H}^{2\pi} |D(\f')| d \f'
}


\I Straightforward by definition
\I Definition
\I Approximation of rectangle to integral





\page [yes] % % % % % % % % % % % % % % % % % % % % % % % % % %


\Frametitle {Proof (3/3)}
\Disp{
R(\f)
\leq &\F{1}{2\pi} \int_{\f'=2\pi L/N_H}^{2\pi} \F{48}{(24 -\f'^2) \f'} d \f'
+\F{2\pi} {N_H} \NT \\
=&\F{1}{\pi} \log \F{2\pi N_H}{L}
-\F{1}{N_H} \log \F{4\pi^2 -24} {L^2/N_H^2 -24}
+\F{2\pi} {N_H} \\
\leq &\F{1}{\pi} \log \F{N_H}{L}.
}


\I Plug in above bound for \m {}
\I Calculation
\I Drop the middle term (\m {}) and last term (small)





\page [yes] % % % % % % % % % % % % % % % % % % % % % % % % % %


\Frametitle {Lemma (Tentative): \m {} is Almost Sparse}
Let \m {} and \m {} be uniformly, independently distributed in \m {}.
Then \m {} is almost-\m {}-sparse with \m {}-residue \m {} to be
\Disp{
R
\leq \F{L}{\pi^2} \left( \log \F{N_H}{L} \right)^2
}

\page [yes] % % % % % % % % % % % % % % % % % % % % % % % % % %



\page [yes] % % % % % % % % % % % % % % % % % % % % % % % % % %


\Frametitle {The Main Bound}
Let \m {} be defined as above, then, for overwhelming probability
\Disp{
\|\V{d}\|_2
\leq \F{4}{\pi^4} \d_{3L}^4 (1-2\d_{2L}) L^4 ( \log N_H )^4
}



\stoptext
